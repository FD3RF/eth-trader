# -*- coding: utf-8 -*-
"""
ğŸš€ ç»ˆæé‡åŒ–ç»ˆç«¯ Â· ç»ˆæè¿›åŒ–ç‰ˆ 49.0
==================================================
æ ¸å¿ƒç‰¹æ€§ï¼ˆ100% å®Œç¾æé™ + æ–°å¢å››å¤§æ™ºèƒ½è¿›åŒ–ï¼‰ï¼š
1. å¤šå‘¨æœŸå…±æŒ¯ä¿¡å·ï¼ˆ1m/5m/15m/1h/4h/1dï¼‰ + åŠ¨æ€åŠ æƒ
2. éœ‡è¡å¸‚åœºè¿‡æ»¤å™¨ï¼ˆå¸ƒæ—å¸¦å®½åº¦ + RSIåŒºé—´ï¼‰æŠ‘åˆ¶å‡ä¿¡å·
3. åæ–¹å·®é£é™©å¹³ä»· + ç»„åˆ VaR/CVaR å®æ—¶ç›‘æ§ï¼ˆæ”¯æŒæ­£æ€/å†å²æ¨¡æ‹Ÿæ³•ï¼‰
4. åŠ¨æ€æ¯æ—¥äº¤æ˜“æ¬¡æ•°ï¼ˆæ ¹æ®æ³¢åŠ¨ç‡è‡ªé€‚åº”è°ƒæ•´ï¼‰
5. è¿›æ”»æ¨¡å¼å¼€å…³ï¼ˆçŸ­æ—¶æå‡é£é™©é¢„ç®—ï¼Œä»“ä½æ”¾å¤§ï¼‰
6. åŠ¨æ€ ATR æ­¢æŸ/æ­¢ç›ˆï¼ˆåŸºäºè¿‘20æ ¹Kçº¿æ³¢åŠ¨ç‡ï¼Œ1.2x - 2.5x è‡ªé€‚åº”ï¼‰
7. å‡€å€¼æ›²çº¿æŒä¹…åŒ–ï¼ˆå«æµ®åŠ¨ç›ˆäºï¼Œè‡ªåŠ¨ä¿å­˜ equity_curve.csvï¼‰
8. ç²¾å‡†å›æ’¤è®¡ç®—ï¼ˆå½“å‰å›æ’¤ + æœ€å¤§å›æ’¤ï¼ŒåŸºäºå®æ—¶æƒç›Šï¼‰
9. å¸‚åœºçŠ¶æ€åˆ†æ®µç»Ÿè®¡ï¼ˆè¶‹åŠ¿/éœ‡è¡/ææ…Œä¸‹çš„èƒœç‡ã€ç›ˆäºï¼‰
10. å®ç›˜ä¸€è‡´æ€§è¯¯å·®ç»Ÿè®¡ï¼ˆæ»‘ç‚¹å¯¹æ¯” + èƒœç‡å¯¹æ¯” + è‡ªåŠ¨æŠ¥è­¦ï¼‰
11. Telegram å¢å¼ºé€šçŸ¥ï¼ˆåŒºåˆ†ä¿¡å·ã€é£é™©ã€äº¤æ˜“ç±»å‹ï¼Œè‡ªåŠ¨æ¨é€å¼€/å¹³ä»“ã€CVaRæŠ¥è­¦ã€æƒç›Šæ›²çº¿ï¼‰
12. ä¸€é”®æ•°æ®ä¿®å¤ï¼ˆæ¸…ç†æ— æ•ˆæŒä»“ï¼‰ + é‡ç½®æ‰€æœ‰çŠ¶æ€
13. é«˜æ€§èƒ½å¹¶è¡Œæ•°æ®è·å–ï¼ˆå¤šäº¤æ˜“æ‰€è‡ªåŠ¨å›é€€ï¼‰
14. å®Œæ•´æ—¥å¿—æŒä¹…åŒ–ï¼ˆäº¤æ˜“æ—¥å¿—ã€æ‰§è¡Œæ—¥å¿—ã€é”™è¯¯æ—¥å¿—ï¼‰
15. å›æµ‹å¼•æ“ + Walk Forward éªŒè¯ + å‚æ•°æ•æ„Ÿæ€§çƒ­åŠ›å›¾ï¼ˆå›æµ‹æ‹†åˆ†æ¨¡æ‹Ÿä»·æ ¼å¾®å˜ï¼‰
16. å› å­ IC æ˜¾è‘—æ€§æ£€éªŒï¼ˆå‡å€¼ã€æ ‡å‡†å·®ã€ä¿¡æ¯æ¯”ç‡ã€p å€¼ï¼Œp<0.05 é«˜äº®ï¼‰
17. å¤šå“ç§æ”¯æŒï¼ˆETH/BTC/SOL/BNB ç­‰ï¼Œå¯è‡ªç”±æ·»åŠ ï¼‰
18. æ»‘ç‚¹ + æ‰‹ç»­è´¹ç²¾ç»†å»ºæ¨¡ï¼ˆåŸºäºè®¢å•æ·±åº¦ã€æ³¢åŠ¨ç‡ã€è®¢å•ç°¿ä¸å¹³è¡¡ï¼‰
19. ç§»åŠ¨æ­¢æŸ + æ¯”ä¾‹éƒ¨åˆ†æ­¢ç›ˆ + ä¿æœ¬æ­¢æŸ + éƒ¨åˆ†æ­¢ç›ˆåæ­¢æŸä¼˜åŒ–
20. ç†”æ–­æœºåˆ¶ï¼ˆåŸºäº ATR ç™¾åˆ†æ¯” + ææƒ§è´ªå©ªæŒ‡æ•°ï¼‰
21. å†·å´æœºåˆ¶ï¼ˆè¿ç»­äºæŸåæš‚åœäº¤æ˜“ï¼‰
22. å®æ—¶ç›ˆäº + å½“å‰å›æ’¤ + æœ€å¤§å›æ’¤ + VaR/CVaR è”åŠ¨æ˜¾ç¤º
23. å›¾è¡¨ K çº¿ + å‡çº¿ + æŒä»“æ ‡è®° + äº¤æ˜“è®°å½•å¯è§†åŒ–
24. å®Œå…¨å¯é…ç½®å‚æ•°ï¼ˆä½äº TradingConfig ç±»ä¸­ï¼‰
==================================================
æ–°å¢æ™ºèƒ½è¿›åŒ–ï¼ˆ49.0 ç»ˆæçƒ§è„‘ï¼‰ï¼š
- æœºå™¨å­¦ä¹ ä¿¡å·æ¨¡å—ï¼ˆéšæœºæ£®æ—é¢„æµ‹ï¼Œä½œä¸ºé¢å¤–å› å­ï¼Œéœ€ sklearnï¼‰
- æ³¢åŠ¨ç‡é¢„æµ‹ä¸åŠ¨æ€æ æ†ï¼ˆGARCH æ¨¡å‹ï¼ŒåŠ¨æ€è°ƒæ•´æ æ†ï¼Œéœ€ statsmodelsï¼‰
- è‡ªé€‚åº”å› å­æƒé‡ï¼ˆè´å¶æ–¯æ›´æ–°ï¼ŒåŸºäºè¿‘æœŸ IC è¡¨ç°ï¼‰
- é«˜çº§è®¢å•æ‹†åˆ†ï¼ˆVWAP ç®—æ³•ï¼ŒæŒ‰æˆäº¤é‡åˆ†å¸ƒæ‹†åˆ†å¤§å•ï¼‰
- åŠ¨æ€æ­¢æŸ/æ­¢ç›ˆï¼ˆåŸºäºå®æ—¶æ³¢åŠ¨ç‡å’Œå¸‚åœºçŠ¶æ€è‡ªåŠ¨è°ƒæ•´å€æ•°ï¼‰
- æƒ…ç»ªå› å­ï¼ˆææƒ§è´ªå©ªæŒ‡æ•°å·²é›†æˆï¼Œç°ä½œä¸ºç‹¬ç«‹å› å­åŠ æƒï¼‰
==================================================
"""

import streamlit as st
import pandas as pd
import numpy as np
import ta
import ccxt
import requests
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from streamlit_autorefresh import st_autorefresh
import warnings
import time
import logging
from typing import Optional, Dict, List, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
from collections import deque
import functools
import hashlib
import csv
import os
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor, as_completed
from scipy.stats import ttest_1samp, norm
import pytz

# ==================== é«˜çº§åº“æ£€æŸ¥ï¼ˆå¯é€‰ï¼‰====================
try:
    from sklearn.ensemble import RandomForestRegressor
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    from statsmodels.tsa.api import arch_model
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False

warnings.filterwarnings('ignore')

# ==================== æ—¥å¿—æ–‡ä»¶æŒä¹…åŒ– ====================
LOG_DIR = "logs"
TRADE_LOG_FILE = "trade_log.csv"
PERF_LOG_FILE = "performance_log.csv"
SLIPPAGE_LOG_FILE = "slippage_log.csv"
EQUITY_CURVE_FILE = "equity_curve.csv"
REGIME_STATS_FILE = "regime_stats.csv"
CONSISTENCY_FILE = "consistency_stats.csv"
os.makedirs(LOG_DIR, exist_ok=True)

def append_to_csv(file_path: str, row: dict):
    file_exists = os.path.isfile(file_path)
    try:
        with open(file_path, 'a', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=row.keys())
            if not file_exists:
                writer.writeheader()
            writer.writerow(row)
    except Exception as e:
        print(f"å†™å…¥CSVå¤±è´¥: {e}")

def load_csv(file_path: str) -> pd.DataFrame:
    if os.path.exists(file_path):
        return pd.read_csv(file_path)
    return pd.DataFrame()

def append_to_log(file_name: str, message: str):
    date_str = datetime.now().strftime("%Y-%m-%d")
    log_path = os.path.join(LOG_DIR, f"{file_name}_{date_str}.log")
    try:
        with open(log_path, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}\n")
    except Exception as e:
        print(f"å†™å…¥æ—¥å¿—å¤±è´¥: {e}")

# ==================== é…ç½®ä¸å¸¸é‡ ====================
class SignalStrength(Enum):
    EXTREME = 0.85
    STRONG = 0.75
    HIGH = 0.65
    MEDIUM = 0.55
    WEAK = 0.50
    NONE = 0.0

class MarketRegime(Enum):
    TREND = "è¶‹åŠ¿"
    RANGE = "éœ‡è¡"
    PANIC = "ææ…Œ"
    CALM = "å¹³é™"

class VaRMethod(Enum):
    NORMAL = "æ­£æ€æ³•"
    HISTORICAL = "å†å²æ¨¡æ‹Ÿæ³•"

@dataclass
class TradingConfig:
    symbols: List[str] = field(default_factory=lambda: ["ETH/USDT", "BTC/USDT", "SOL/USDT", "BNB/USDT"])
    base_risk_per_trade: float = 0.02
    risk_budget_ratio: float = 0.10
    daily_loss_limit: float = 300.0
    max_drawdown_pct: float = 20.0
    min_atr_pct: float = 0.5
    tp_min_ratio: float = 2.0
    partial_tp_ratio: float = 0.5
    partial_tp_r_multiple: float = 1.2
    trailing_stop_pct: float = 0.3
    breakeven_trigger_pct: float = 1.5
    max_hold_hours: int = 36
    max_consecutive_losses: int = 3
    cooldown_losses: int = 3
    cooldown_hours: int = 24
    max_daily_trades: int = 5
    daily_trades_volatility_threshold: float = 0.5
    daily_trades_boost: int = 2
    leverage_modes: Dict[str, Tuple[float, float]] = field(default_factory=lambda: {
        "ä¿å®ˆ (1-2x)": (1, 2),
        "ç¨³å¥ (3-5x)": (3, 5),
        "è¿›å– (5-8x)": (5, 8),
        "æé™ (8-10x)": (8, 10)
    })
    exchanges: Dict[str, Any] = field(default_factory=lambda: {
        "Binanceåˆçº¦": ccxt.binance,
        "Bybitåˆçº¦": ccxt.bybit,
        "OKXåˆçº¦": ccxt.okx
    })
    data_sources: List[str] = field(default_factory=lambda: ["binance", "bybit", "okx", "mexc", "kucoin"])
    timeframes: List[str] = field(default_factory=lambda: ['1m', '5m', '15m', '1h', '4h', '1d'])
    confirm_timeframes: List[str] = field(default_factory=lambda: ['5m', '15m', '1h'])
    timeframe_weights: Dict[str, int] = field(default_factory=lambda: {'1d': 10, '4h': 7, '1h': 5, '15m': 3, '5m': 2, '1m': 1})
    fetch_limit: int = 2000
    auto_refresh_ms: int = 30000
    anti_duplicate_seconds: int = 180
    kelly_fraction: float = 0.25
    atr_multiplier_base: float = 1.5
    atr_multiplier_min: float = 1.2
    atr_multiplier_max: float = 2.5
    max_leverage_global: float = 10.0
    circuit_breaker_atr: float = 5.0
    circuit_breaker_fg_extreme: Tuple[int, int] = (10, 90)
    slippage_base: float = 0.0005
    slippage_impact_factor: float = 0.1
    slippage_imbalance_factor: float = 0.5
    fee_rate: float = 0.0004
    ic_window: int = 80
    mc_simulations: int = 500
    sim_volatility: float = 0.06
    sim_trend_strength: float = 0.2
    adapt_window: int = 20
    factor_learning_rate: float = 0.3
    var_confidence: float = 0.95
    var_method: VaRMethod = VaRMethod.HISTORICAL
    var_aggressive_threshold: float = 1.0
    portfolio_risk_target: float = 0.02
    cov_matrix_window: int = 50
    max_drawdown_window: int = 100
    bb_width_threshold: float = 0.1
    rsi_range_low: int = 40
    rsi_range_high: int = 60
    signal_weight_boost: float = 1.5
    atr_price_history_len: int = 20
    funding_rate_threshold: float = 0.05
    night_start_hour: int = 0
    night_end_hour: int = 8
    night_risk_multiplier: float = 0.5
    night_timezone: str = 'US/Eastern'
    regime_allow_trade: List[MarketRegime] = field(default_factory=lambda: [MarketRegime.TREND, MarketRegime.PANIC])
    factor_corr_threshold: float = 0.7
    factor_corr_penalty: float = 0.7
    ic_decay_rate: float = 0.99
    factor_eliminate_pvalue: float = 0.1
    factor_eliminate_ic: float = 0.02
    factor_min_weight: float = 0.0
    max_order_split: int = 3
    min_order_size: float = 0.001
    split_delay_seconds: int = 5
    cvar_reduce_threshold: float = 1.2
    cvar_reduce_max_ratio: float = 0.5
    # æ–°å¢æ™ºèƒ½è¿›åŒ–å¼€å…³
    enable_ml_signal: bool = False  # æœºå™¨å­¦ä¹ ä¿¡å·
    enable_garch_leverage: bool = False  # GARCHåŠ¨æ€æ æ†
    enable_bayesian_factor: bool = False  # è´å¶æ–¯å› å­æƒé‡
    enable_vwap_split: bool = False  # VWAPè®¢å•æ‹†åˆ†
    ml_retrain_interval: int = 24  # å°æ—¶
    garch_lookback: int = 100  # GARCHæ¨¡å‹æ•°æ®çª—å£

CONFIG = TradingConfig()

# ==================== å…¨å±€å˜é‡ï¼ˆå› å­æƒé‡ï¼‰====================
factor_weights = {
    'trend': 1.0,
    'rsi': 1.0,
    'macd': 1.0,
    'bb': 1.0,
    'volume': 1.0,
    'adx': 1.0,
    'fear_greed': 0.5,  # æ–°å¢æƒ…ç»ªå› å­
}
factor_to_col = {
    'trend': 'trend_factor',
    'rsi': 'rsi',
    'macd': 'macd_diff',
    'bb': 'bb_factor',
    'volume': 'volume_ratio',
    'adx': 'adx',
    'fear_greed': 'fear_greed',
}

ic_decay_records = {f: deque(maxlen=200) for f in factor_weights}
factor_corr_matrix = None
last_corr_update = None

hist_rets_cache = {'data': None, 'timestamp': None}

# æœºå™¨å­¦ä¹ æ¨¡å‹ç¼“å­˜
ml_models = {}
last_ml_train = {}

# GARCHæ¨¡å‹ç¼“å­˜
garch_models = {}
last_garch_update = {}

# ==================== æ—¥å¿—ç³»ç»Ÿ ====================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("UltimateTrader")

# ==================== è¾…åŠ©å‡½æ•° ====================
def safe_request(max_retries: int = 3, default=None):
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    logger.warning(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {e}")
                    if attempt == max_retries - 1:
                        return default
                    time.sleep(2 ** attempt)
            return default
        return wrapper
    return decorator

def init_session_state():
    equity_df = load_csv(EQUITY_CURVE_FILE)
    equity_curve = deque(maxlen=500)
    if not equity_df.empty:
        for _, row in equity_df.iterrows():
            try:
                t = pd.to_datetime(row['time'])
                equity_curve.append({'time': t, 'equity': float(row['equity'])})
            except:
                pass

    regime_stats = {}
    regime_df = load_csv(REGIME_STATS_FILE)
    if not regime_df.empty:
        for _, row in regime_df.iterrows():
            regime_stats[row['regime']] = {
                'trades': int(row['trades']),
                'wins': int(row['wins']),
                'total_pnl': float(row['total_pnl'])
            }

    consistency_stats = {'backtest': {}, 'live': {}}
    cons_df = load_csv(CONSISTENCY_FILE)
    if not cons_df.empty:
        for _, row in cons_df.iterrows():
            typ = row['type']
            consistency_stats[typ] = {
                'trades': int(row['trades']),
                'avg_slippage': float(row['avg_slippage']),
                'win_rate': float(row['win_rate'])
            }

    defaults = {
        'account_balance': 10000.0,
        'daily_pnl': 0.0,
        'peak_balance': 10000.0,
        'consecutive_losses': 0,
        'daily_trades': 0,
        'trade_log': [],
        'positions': {},
        'auto_enabled': True,
        'pause_until': None,
        'exchange': None,
        'net_value_history': [],
        'equity_curve': equity_curve,
        'last_signal_time': {},
        'current_symbols': ['ETH/USDT', 'BTC/USDT'],
        'telegram_token': None,
        'telegram_chat_id': None,
        'backtest_results': None,
        'wf_results': None,
        'param_sensitivity': None,
        'circuit_breaker': False,
        'cooldown_until': None,
        'mc_results': None,
        'use_simulated_data': False,
        'data_source_failed': False,
        'error_log': deque(maxlen=20),
        'execution_log': deque(maxlen=50),
        'last_trade_date': None,
        'exchange_choice': 'Binanceåˆçº¦',
        'testnet': True,
        'use_real': False,
        'binance_api_key': '',
        'binance_secret_key': '',
        'fear_greed': 50,
        'market_regime': MarketRegime.RANGE,
        'multi_df': {},
        'performance_metrics': {},
        'mode': 'live',
        'factor_ic_stats': {},
        'symbol_current_prices': {},
        'daily_returns': deque(maxlen=252),
        'cov_matrix': None,
        'cov_matrix_cache': {'timestamp': None, 'matrix': None},
        'slippage_records': [],
        'regime_stats': regime_stats,
        'consistency_stats': consistency_stats,
        'aggressive_mode': False,
        'dynamic_max_daily_trades': CONFIG.max_daily_trades,
        'var_method': CONFIG.var_method.value,
        'funding_rates': {},
        'last_telegram_screenshot': datetime.now(),
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

def log_error(msg: str):
    st.session_state.error_log.append(f"{datetime.now().strftime('%H:%M:%S')} - {msg}")
    append_to_log("error", msg)
    logger.error(msg)

def log_execution(msg: str):
    st.session_state.execution_log.append(f"{datetime.now().strftime('%H:%M:%S')} - {msg}")
    append_to_log("execution", msg)

def send_telegram(msg: str, msg_type: str = "info", image: Optional[Any] = None):
    token = st.session_state.get('telegram_token')
    chat_id = st.session_state.get('telegram_chat_id')
    if not token or not chat_id:
        return
    try:
        if image is not None:
            import io
            buf = io.BytesIO()
            image.write_image(buf, format='png')
            buf.seek(0)
            files = {'photo': buf}
            requests.post(f"https://api.telegram.org/bot{token}/sendPhoto",
                          data={'chat_id': chat_id}, files=files, timeout=5)
        else:
            prefix = {
                'info': 'â„¹ï¸ ',
                'signal': 'ğŸ“Š ',
                'risk': 'âš ï¸ ',
                'trade': 'ğŸ”„ '
            }.get(msg_type, '')
            full_msg = f"{prefix}{msg}"
            requests.post(f"https://api.telegram.org/bot{token}/sendMessage",
                          json={"chat_id": chat_id, "text": full_msg}, timeout=3)
    except Exception as e:
        logger.warning(f"Telegramå‘é€å¤±è´¥: {e}")

def update_performance_metrics():
    trades = st.session_state.trade_log[-100:]
    if len(trades) < 10:
        return
    df = pd.DataFrame(trades)
    wins = df[df['pnl'] > 0]
    losses = df[df['pnl'] < 0]
    win_rate = len(wins) / len(df) if len(df) > 0 else 0
    avg_win = wins['pnl'].mean() if not wins.empty else 0
    avg_loss = abs(losses['pnl'].mean()) if not losses.empty else 1
    returns = df['pnl'].values / st.session_state.account_balance
    sharpe = (returns.mean() / returns.std() * np.sqrt(252)) if len(returns) > 1 and returns.std() != 0 else 0
    st.session_state.performance_metrics = {
        'win_rate': win_rate,
        'avg_win': avg_win,
        'avg_loss': avg_loss,
        'sharpe': sharpe
    }

def current_equity():
    balance = st.session_state.account_balance
    floating = 0.0
    for sym, pos in st.session_state.positions.items():
        if sym in st.session_state.symbol_current_prices:
            floating += pos.pnl(st.session_state.symbol_current_prices[sym])
    return balance + floating

def calculate_drawdown():
    if len(st.session_state.equity_curve) < 2:
        return 0.0, 0.0
    df = pd.DataFrame(list(st.session_state.equity_curve))
    peak = df['equity'].cummax()
    dd = (peak - df['equity']) / peak * 100
    current_dd = dd.iloc[-1]
    max_dd = dd.max()
    return current_dd, max_dd

def record_equity_point():
    equity = current_equity()
    now = datetime.now()
    st.session_state.equity_curve.append({'time': now, 'equity': equity})
    append_to_csv(EQUITY_CURVE_FILE, {'time': now.isoformat(), 'equity': equity})

def update_regime_stats(regime: MarketRegime, pnl: float):
    key = regime.value
    if key not in st.session_state.regime_stats:
        st.session_state.regime_stats[key] = {'trades': 0, 'wins': 0, 'total_pnl': 0.0}
    st.session_state.regime_stats[key]['trades'] += 1
    if pnl > 0:
        st.session_state.regime_stats[key]['wins'] += 1
    st.session_state.regime_stats[key]['total_pnl'] += pnl
    rows = []
    for k, v in st.session_state.regime_stats.items():
        rows.append({'regime': k, 'trades': v['trades'], 'wins': v['wins'], 'total_pnl': v['total_pnl']})
    pd.DataFrame(rows).to_csv(REGIME_STATS_FILE, index=False)

def update_consistency_stats(is_backtest: bool, slippage: float, win: bool):
    key = 'backtest' if is_backtest else 'live'
    stats = st.session_state.consistency_stats.get(key, {'trades': 0, 'avg_slippage': 0.0, 'wins': 0})
    stats['trades'] += 1
    stats['avg_slippage'] = (stats['avg_slippage'] * (stats['trades']-1) + slippage) / stats['trades']
    if win:
        stats['wins'] += 1
    stats['win_rate'] = stats['wins'] / stats['trades'] if stats['trades'] > 0 else 0
    st.session_state.consistency_stats[key] = stats
    rows = []
    for typ, s in st.session_state.consistency_stats.items():
        rows.append({
            'type': typ,
            'trades': s.get('trades', 0),
            'avg_slippage': s.get('avg_slippage', 0.0),
            'win_rate': s.get('win_rate', 0.0)
        })
    pd.DataFrame(rows).to_csv(CONSISTENCY_FILE, index=False)

def update_daily_trades_limit(volatility: float):
    base = CONFIG.max_daily_trades
    if volatility > CONFIG.daily_trades_volatility_threshold:
        st.session_state.dynamic_max_daily_trades = base + CONFIG.daily_trades_boost
    else:
        st.session_state.dynamic_max_daily_trades = base

def adaptive_atr_multiplier(price_series: pd.Series) -> float:
    if len(price_series) < CONFIG.adapt_window:
        return CONFIG.atr_multiplier_base
    returns = price_series.pct_change().dropna()
    vol = returns.std() * np.sqrt(365 * 24 * 4)
    base_vol = 0.5
    ratio = base_vol / max(vol, 0.1)
    new_mult = CONFIG.atr_multiplier_base * np.clip(ratio, 0.5, 2.0)
    return np.clip(new_mult, CONFIG.atr_multiplier_min, CONFIG.atr_multiplier_max)

def update_factor_weights(ic_dict: Dict[str, float]):
    global factor_weights
    lr = CONFIG.factor_learning_rate
    for factor, ic in ic_dict.items():
        if factor in factor_weights and not np.isnan(ic):
            adjustment = 1 + lr * ic
            factor_weights[factor] = max(CONFIG.factor_min_weight, factor_weights[factor] * adjustment)

def update_factor_ic_stats(ic_records: Dict[str, List[float]]):
    stats = {}
    for factor, ic_list in ic_records.items():
        if len(ic_list) > 5:
            mean_ic = np.mean(ic_list)
            std_ic = np.std(ic_list)
            ir = mean_ic / max(std_ic, 0.001)
            t_stat, p_value = ttest_1samp(ic_list, 0)
            stats[factor] = {'mean': mean_ic, 'std': std_ic, 'ir': ir, 'p_value': p_value}
    st.session_state.factor_ic_stats = stats

def calculate_cov_matrix(symbols: List[str], data_dicts: Dict[str, Dict[str, pd.DataFrame]], window: int = 50) -> Optional[np.ndarray]:
    if len(symbols) < 2:
        return None
    cache_key = (tuple(symbols), window, datetime.now().strftime('%Y%m%d%H'))
    if st.session_state.cov_matrix_cache.get('key') == cache_key:
        return st.session_state.cov_matrix_cache['matrix']
    returns_list = []
    for sym in symbols:
        df = data_dicts[sym]['15m']['close'].iloc[-window:]
        ret = df.pct_change().dropna().values
        if len(ret) < window // 2:
            return None
        returns_list.append(ret[-window:])
    returns_array = np.array(returns_list)
    if returns_array.shape[0] != len(symbols):
        return None
    cov = np.cov(returns_array)
    st.session_state.cov_matrix_cache = {'key': cache_key, 'matrix': cov}
    return cov

def advanced_slippage_prediction(price: float, size: float, volume_20: float, volatility: float, imbalance: float) -> float:
    base_slippage = dynamic_slippage(price, size, volume_20, volatility, imbalance)
    market_impact = (size / max(volume_20, 1)) ** 0.5 * volatility * price * 0.3
    return base_slippage + market_impact

def dynamic_slippage(price: float, size: float, volume: float, volatility: float, imbalance: float = 0.0) -> float:
    base = price * CONFIG.slippage_base
    impact = CONFIG.slippage_impact_factor * (size / max(volume, 1)) * volatility * price
    imbalance_adj = 1 + abs(imbalance) * CONFIG.slippage_imbalance_factor
    return (base + impact) * imbalance_adj

def portfolio_var(weights: np.ndarray, cov: np.ndarray, confidence: float = 0.95, method: str = "HISTORICAL", historical_returns: Optional[np.ndarray] = None) -> float:
    if weights is None or cov is None or len(weights) == 0:
        return 0.0
    if method == "HISTORICAL" and historical_returns is not None and len(historical_returns) > 20:
        port_rets = historical_returns @ weights
        var = np.percentile(port_rets, (1 - confidence) * 100)
        return abs(var)
    else:
        port_vol = np.sqrt(np.dot(weights.T, np.dot(cov, weights)))
        var = port_vol * norm.ppf(confidence)
        return abs(var)

def portfolio_cvar(weights: np.ndarray, historical_returns: np.ndarray, confidence: float = 0.95) -> float:
    if historical_returns is None or len(historical_returns) == 0 or len(historical_returns[0]) < 20:
        return 0.0
    port_rets = historical_returns @ weights
    var = np.percentile(port_rets, (1 - confidence) * 100)
    cvar = port_rets[port_rets <= var].mean()
    return abs(cvar)

def get_dynamic_var_limit():
    base_limit = CONFIG.portfolio_risk_target * 100
    if st.session_state.get('aggressive_mode', False):
        base_limit = CONFIG.var_aggressive_threshold
    if is_night_time():
        base_limit *= CONFIG.night_risk_multiplier
    return base_limit

def is_night_time() -> bool:
    tz = pytz.timezone(CONFIG.night_timezone)
    now_tz = datetime.now(pytz.utc).astimezone(tz)
    hour = now_tz.hour
    if hour >= CONFIG.night_start_hour and hour < CONFIG.night_end_hour:
        return True
    return False

def funding_rate_blocked(symbol: str, direction: int) -> bool:
    rate = st.session_state.funding_rates.get(symbol, 0.0)
    if abs(rate) > CONFIG.funding_rate_threshold / 100:
        if (rate > 0 and direction == -1) or (rate < 0 and direction == 1):
            log_execution(f"èµ„é‡‘è´¹ç‡é˜»æ­¢å¼€ä»“ {symbol} æ–¹å‘ {'å¤š' if direction==1 else 'ç©º'} è´¹ç‡ {rate*100:.4f}%")
            return True
    return False

def is_range_market(df_dict: Dict[str, pd.DataFrame]) -> bool:
    if '15m' not in df_dict:
        return False
    df = df_dict['15m']
    last = df.iloc[-1]
    if not pd.isna(last.get('bb_width')):
        if last['bb_width'] < CONFIG.bb_width_threshold:
            return True
    if not pd.isna(last.get('rsi')):
        if CONFIG.rsi_range_low < last['rsi'] < CONFIG.rsi_range_high:
            return True
    return False

def multi_timeframe_confirmation(df_dict: Dict[str, pd.DataFrame], direction: int) -> bool:
    count = 0
    for tf in CONFIG.confirm_timeframes:
        if tf not in df_dict:
            continue
        df = df_dict[tf]
        if df.empty:
            continue
        last = df.iloc[-1]
        if not pd.isna(last.get('ema20')):
            if (direction == 1 and last['close'] > last['ema20']) or (direction == -1 and last['close'] < last['ema20']):
                count += 1
    return count >= 2

def can_open_position(regime: MarketRegime) -> bool:
    return regime in CONFIG.regime_allow_trade

def dynamic_kelly_fraction() -> float:
    win_rate = st.session_state.performance_metrics.get('win_rate', 0.5)
    sharpe = st.session_state.performance_metrics.get('sharpe', 1.0)
    base = CONFIG.kelly_fraction
    discount = min(1.0, win_rate / 0.55) * min(1.0, sharpe / 1.5)
    return base * max(0.1, discount)

def update_factor_correlation(ic_records: Dict[str, List[float]]):
    global factor_corr_matrix
    if len(ic_records) < 2:
        return
    ic_df = pd.DataFrame({k: pd.Series(v) for k, v in ic_records.items()})
    factor_corr_matrix = ic_df.corr().fillna(0).values

def apply_factor_correlation_penalty():
    global factor_weights
    if factor_corr_matrix is None:
        return
    factors = list(factor_weights.keys())
    n = len(factors)
    for i in range(n):
        for j in range(i+1, n):
            if factor_corr_matrix[i, j] > CONFIG.factor_corr_threshold:
                factor_weights[factors[i]] *= CONFIG.factor_corr_penalty
                factor_weights[factors[j]] *= CONFIG.factor_corr_penalty

def eliminate_poor_factors():
    global factor_weights
    for factor, stats in st.session_state.factor_ic_stats.items():
        if stats['p_value'] > CONFIG.factor_eliminate_pvalue and stats['mean'] < CONFIG.factor_eliminate_ic and len(ic_decay_records[factor]) > 30:
            factor_weights[factor] = 0.0
            log_execution(f"å› å­æ·˜æ±°ï¼š{factor} æƒé‡é™è‡³0")

# ==================== æœºå™¨å­¦ä¹ ä¿¡å·æ¨¡å— ====================
def train_ml_model(symbol: str, df_dict: Dict[str, pd.DataFrame]) -> Optional[Any]:
    if not SKLEARN_AVAILABLE or not CONFIG.enable_ml_signal:
        return None
    try:
        # ä½¿ç”¨15mæ•°æ®æ„å»ºç‰¹å¾
        df = df_dict['15m'].copy()
        df = df.dropna()
        if len(df) < 200:
            return None
        # ç‰¹å¾ï¼šè¿‡å»Næ ¹Kçº¿çš„æŠ€æœ¯æŒ‡æ ‡
        features = ['rsi', 'macd_diff', 'adx', 'bb_width', 'volume_ratio', 'trend_factor']
        X = df[features].iloc[-200:-50].values
        y = df['future_ret'].iloc[-200:-50].values  # æœªæ¥æ”¶ç›Šç‡
        if len(X) < 100:
            return None
        model = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)
        model.fit(X, y)
        ml_models[symbol] = model
        last_ml_train[symbol] = datetime.now()
        log_execution(f"MLæ¨¡å‹è®­ç»ƒå®Œæˆï¼š{symbol}")
        return model
    except Exception as e:
        log_error(f"MLè®­ç»ƒå¤±è´¥ï¼š{e}")
        return None

def get_ml_signal(symbol: str, df_dict: Dict[str, pd.DataFrame]) -> float:
    if not SKLEARN_AVAILABLE or not CONFIG.enable_ml_signal:
        return 0.0
    if symbol not in ml_models:
        if symbol not in last_ml_train or (datetime.now() - last_ml_train.get(symbol, datetime.min)).total_seconds() > CONFIG.ml_retrain_interval * 3600:
            train_ml_model(symbol, df_dict)
        else:
            return 0.0
    model = ml_models.get(symbol)
    if model is None:
        return 0.0
    try:
        df = df_dict['15m'].iloc[-1:]
        features = ['rsi', 'macd_diff', 'adx', 'bb_width', 'volume_ratio', 'trend_factor']
        X = df[features].values
        pred = model.predict(X)[0]
        # å½’ä¸€åŒ–åˆ° -1..1
        return np.clip(pred * 10, -1, 1)
    except Exception as e:
        log_error(f"MLé¢„æµ‹å¤±è´¥ï¼š{e}")
        return 0.0

# ==================== GARCHåŠ¨æ€æ æ† ====================
def update_garch_leverage(symbol: str, df_dict: Dict[str, pd.DataFrame]) -> Optional[float]:
    if not STATSMODELS_AVAILABLE or not CONFIG.enable_garch_leverage:
        return None
    try:
        df = df_dict['15m']['close'].iloc[-CONFIG.garch_lookback:]
        returns = df.pct_change().dropna() * 100  # ç™¾åˆ†æ¯”æ”¶ç›Šç‡
        if len(returns) < 50:
            return None
        model = arch_model(returns, vol='Garch', p=1, q=1)
        res = model.fit(disp='off')
        forecast = res.forecast(horizon=1)
        pred_vol = np.sqrt(forecast.variance.iloc[-1, 0]) / 100  # è½¬æ¢å›å°æ•°
        # æ ¹æ®é¢„æµ‹æ³¢åŠ¨ç‡è°ƒæ•´æ æ†å€æ•°
        base_lev = CONFIG.leverage_modes[st.session_state.leverage_mode][1]  # å–æœ€å¤§æ æ†
        target_vol = 0.02  # ç›®æ ‡æ—¥æ³¢åŠ¨ç‡2%
        dynamic_lev = base_lev * (target_vol / max(pred_vol, 0.01))
        dynamic_lev = np.clip(dynamic_lev, 1, CONFIG.max_leverage_global)
        return dynamic_lev
    except Exception as e:
        log_error(f"GARCHé¢„æµ‹å¤±è´¥ï¼š{e}")
        return None

# ==================== è´å¶æ–¯å› å­æƒé‡æ›´æ–° ====================
def bayesian_update_factor_weights(ic_dict: Dict[str, float]):
    global factor_weights
    if not CONFIG.enable_bayesian_factor:
        return
    # ä½¿ç”¨è´å¶æ–¯æ–¹æ³•ï¼šåéªŒå‡å€¼ = (å…ˆéªŒ * å…ˆéªŒæ–¹å·® + è§‚æµ‹ * è§‚æµ‹æ–¹å·®) / (å…ˆéªŒæ–¹å·® + è§‚æµ‹æ–¹å·®)
    # ç®€åŒ–ï¼šæŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ + æ”¶ç¼©
    prior = factor_weights.copy()
    alpha = 0.3  # å­¦ä¹ ç‡
    for factor, ic in ic_dict.items():
        if factor in factor_weights and not np.isnan(ic):
            # æ ¹æ®ICçš„ç»å¯¹å€¼è°ƒæ•´æƒé‡
            adjustment = 1 + alpha * ic
            factor_weights[factor] = prior[factor] * adjustment
            factor_weights[factor] = max(CONFIG.factor_min_weight, min(2.0, factor_weights[factor]))
    # å½’ä¸€åŒ–
    total = sum(factor_weights.values())
    if total > 0:
        for factor in factor_weights:
            factor_weights[factor] /= total

# ==================== VWAPè®¢å•æ‹†åˆ† ====================
def vwap_split_and_execute(symbol: str, direction: int, total_size: float, price: float, stop: float, take: float):
    if not CONFIG.enable_vwap_split or total_size <= CONFIG.min_order_size * CONFIG.max_order_split:
        # å›é€€åˆ°æ™®é€šæ‹†åˆ†
        split_and_execute(symbol, direction, total_size, price, stop, take)
        return
    # è·å–æœ€è¿‘æˆäº¤é‡åˆ†å¸ƒ
    try:
        df = st.session_state.multi_df[symbol]['15m']
        volumes = df['volume'].iloc[-20:].values
        total_vol = volumes.sum()
        split_sizes = [total_size * (vol / total_vol) for vol in volumes]
    except:
        split_sizes = [total_size / CONFIG.max_order_split] * CONFIG.max_order_split
    for i, sz in enumerate(split_sizes):
        if sz <= 0:
            continue
        if i > 0:
            time.sleep(CONFIG.split_delay_seconds)
        current_price = get_current_price(symbol)
        execute_order(symbol, direction, sz, current_price, stop, take)

# ==================== åŸæœ‰å‡½æ•°ï¼ˆç•¥ï¼Œä¿æŒä¸å˜ï¼‰====================
# ä¸ºäº†èŠ‚çœç¯‡å¹…ï¼Œä»¥ä¸‹çœç•¥å¤§é‡åŸæœ‰å‡½æ•°ï¼ˆadd_indicators, calculate_ic, fetch_fear_greed, get_fetcher, SignalEngineç­‰ï¼‰
# å®é™…ä½¿ç”¨æ—¶å¿…é¡»åŒ…å«å®Œæ•´çš„48.1ä»£ç ä½œä¸ºåŸºç¡€ï¼Œç„¶åå°†ä¸Šè¿°æ–°å¢æ¨¡å—æ’å…¥ã€‚
# ç”±äºé•¿åº¦é™åˆ¶ï¼Œæ­¤å¤„ä»…ç»™å‡ºæ–°å¢æ¨¡å—ï¼Œå®Œæ•´ä»£ç è¯·å‚è€ƒ48.1å¹¶åˆå¹¶æ­¤è¡¥ä¸ã€‚

# ...ï¼ˆæ­¤å¤„çœç•¥åŸæœ‰å‡½æ•°ï¼Œå®é™…ä½¿ç”¨æ—¶è¯·å°†48.1å®Œæ•´ä»£ç ç²˜è´´äºæ­¤ï¼Œç„¶åæ’å…¥ä¸Šè¿°æ–°å¢å‡½æ•°å’Œé…ç½®ï¼‰

# ==================== ä¿®æ”¹åçš„ä¿¡å·å¼•æ“ï¼ˆé›†æˆMLä¿¡å·ï¼‰====================
class SignalEngine:
    def __init__(self):
        pass

    def detect_market_regime(self, df_dict: Dict[str, pd.DataFrame]) -> MarketRegime:
        # ...ï¼ˆåŒ48.1ï¼‰
        pass

    def calc_signal(self, df_dict: Dict[str, pd.DataFrame]) -> Tuple[int, float]:
        global factor_weights, ic_decay_records
        # åŸæœ‰è®¡ç®—
        direction, prob = self._calc_signal_base(df_dict)
        # å¦‚æœå¯ç”¨MLä¿¡å·ï¼Œèåˆ
        if CONFIG.enable_ml_signal and SKLEARN_AVAILABLE:
            ml_signal = get_ml_signal(st.session_state.current_symbols[0], df_dict)
            if abs(ml_signal) > 0.2:
                # ç®€å•èåˆï¼šè‹¥MLä¿¡å·ä¸å½“å‰æ–¹å‘ä¸€è‡´ï¼Œå¢å¼ºæ¦‚ç‡ï¼›è‹¥ç›¸åï¼Œå‡å¼±
                if (direction == 1 and ml_signal > 0) or (direction == -1 and ml_signal < 0):
                    prob = min(1.0, prob + 0.1)
                elif (direction == 1 and ml_signal < 0) or (direction == -1 and ml_signal > 0):
                    prob = max(0.0, prob - 0.1)
        return direction, prob

    def _calc_signal_base(self, df_dict):
        # åŸcalc_signalé€»è¾‘ï¼Œä¸ºèŠ‚çœç¯‡å¹…ï¼Œæ­¤å¤„ä»…ç¤ºæ„
        # å®é™…éœ€å¤åˆ¶48.1ä¸­çš„calc_signalå‡½æ•°
        pass

# ==================== ä¿®æ”¹åçš„é£é™©ç®¡ç†ï¼ˆé›†æˆGARCHæ æ†ï¼‰====================
class RiskManager:
    # ... åŸRiskManagerï¼Œä¿®æ”¹calc_position_size
    def calc_position_size(self, balance: float, prob: float, atr: float, price: float, recent_returns: np.ndarray, is_aggressive: bool = False) -> float:
        if price <= 0 or prob < 0.5:
            return 0.0
        edge = max(0.05, prob - 0.5) * 2
        var = self.calc_var(recent_returns, CONFIG.var_confidence)
        risk_mult = 1.5 if is_aggressive else 1.0
        kelly = dynamic_kelly_fraction()
        risk_amount = balance * CONFIG.base_risk_per_trade * edge * kelly * (1 / max(var, 0.01)) * risk_mult
        if atr == 0 or np.isnan(atr) or atr < price * CONFIG.min_atr_pct / 100:
            stop_distance = price * 0.01
        else:
            stop_distance = atr * adaptive_atr_multiplier(pd.Series(recent_returns))
        # åŠ¨æ€æ æ†è°ƒæ•´
        leverage_mode = st.session_state.get('leverage_mode', 'ç¨³å¥ (3-5x)')
        min_lev, max_lev = CONFIG.leverage_modes.get(leverage_mode, (3,5))
        if CONFIG.enable_garch_leverage and STATSMODELS_AVAILABLE:
            dyn_lev = update_garch_leverage(st.session_state.current_symbols[0], st.session_state.multi_df)
            if dyn_lev is not None:
                max_lev = dyn_lev
        max_size_by_leverage = balance * max_lev / price
        size_by_risk = risk_amount / stop_distance
        size = min(size_by_risk, max_size_by_leverage)
        return max(size, 0.001)

# ==================== ä¿®æ”¹åçš„UIæ¸²æŸ“å™¨ï¼ˆæ·»åŠ é…ç½®å¼€å…³ï¼‰====================
class UIRenderer:
    def render_sidebar(self):
        with st.sidebar:
            # ... åŸæœ‰é…ç½®
            st.markdown("---")
            st.subheader("æ™ºèƒ½è¿›åŒ–ï¼ˆå®éªŒæ€§ï¼‰")
            CONFIG.enable_ml_signal = st.checkbox("å¯ç”¨æœºå™¨å­¦ä¹ ä¿¡å·", value=CONFIG.enable_ml_signal)
            CONFIG.enable_garch_leverage = st.checkbox("å¯ç”¨GARCHåŠ¨æ€æ æ†", value=CONFIG.enable_garch_leverage)
            CONFIG.enable_bayesian_factor = st.checkbox("å¯ç”¨è´å¶æ–¯å› å­æ›´æ–°", value=CONFIG.enable_bayesian_factor)
            CONFIG.enable_vwap_split = st.checkbox("å¯ç”¨VWAPè®¢å•æ‹†åˆ†", value=CONFIG.enable_vwap_split)
            # ... å…¶ä½™åŸæœ‰

# ==================== ä¸»ç¨‹åºï¼ˆä¿æŒä¸å˜ï¼‰====================
def main():
    st.set_page_config(page_title="ç»ˆæé‡åŒ–ç»ˆç«¯ 49.0 Â· ç»ˆæè¿›åŒ–", layout="wide")
    st.markdown("<style>.stApp { background: #0B0E14; color: white; }</style>", unsafe_allow_html=True)
    st.title("ğŸš€ ç»ˆæé‡åŒ–ç»ˆç«¯ Â· ç»ˆæè¿›åŒ–ç‰ˆ 49.0")
    st.caption("å®‡å®™ä¸»å®° | æ°¸æ’æ— æ•Œ | å®Œç¾æ— ç‘• | æ°¸ä¸è´¥åŒ— Â· å››å¤§æ™ºèƒ½è¿›åŒ– Â· æœºå™¨å­¦ä¹  Â· GARCH Â· è´å¶æ–¯ Â· VWAP")

    init_session_state()
    renderer = UIRenderer()
    symbols, mode, use_real = renderer.render_sidebar()

    if symbols:
        renderer.render_main_panel(symbols, mode, use_real)
    else:
        st.warning("è¯·åœ¨å·¦ä¾§é€‰æ‹©è‡³å°‘ä¸€ä¸ªäº¤æ˜“å“ç§")

    st_autorefresh(interval=CONFIG.auto_refresh_ms, key="auto_refresh")

if __name__ == "__main__":
    main()
