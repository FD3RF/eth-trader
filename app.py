# -*- coding: utf-8 -*-
"""
ğŸš€ ç»ˆæé‡åŒ–ç»ˆç«¯ Â· æœºæ„ç‰ˆ 55.0ï¼ˆæœ€ç»ˆå®Œç¾ç‰ˆï¼‰
===================================================
æ ¸å¿ƒç‰¹æ€§ï¼š
- å®Œå…¨è§£è€¦ï¼šä¸šåŠ¡é€»è¾‘ä¸UIåˆ†ç¦»ï¼Œä¾èµ–æ³¨å…¥å®¹å™¨ç®¡ç†å¯¹è±¡å›¾
- å›æµ‹å¼•æ“ï¼šæ”¯æŒçœŸå®å†å²æ•°æ®ã€æ»‘ç‚¹ã€æ‰‹ç»­è´¹æ¨¡æ‹Ÿ
- å¼ºåŒ–å­¦ä¹ ï¼šè§‚æµ‹ç©ºé—´æ¥å…¥çœŸå®å¸‚åœºæŒ‡æ ‡ï¼Œå¯è®­ç»ƒPPOæ¨¡å‹
- ç›‘æ§å®Œå–„ï¼šPrometheusæŒ‡æ ‡å®æ—¶æ›´æ–°
- ä»£ç ä¼˜åŒ–ï¼šæŠ½å–å·¥å…·ç±»ï¼Œæ¶ˆé™¤å†—ä½™
===================================================
"""

import streamlit as st
import pandas as pd
import numpy as np
import ta
import ccxt
import ccxt.async_support as ccxt_async
import requests
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from streamlit_autorefresh import st_autorefresh
import asyncio
import aiohttp
import warnings
import time
import logging
import sys
import traceback
from typing import Optional, Dict, List, Tuple, Any, Union, Callable, Deque
from dataclasses import dataclass, field, asdict
from enum import Enum
from collections import deque, defaultdict
import functools
import hashlib
import csv
import os
import json
import yaml
from pathlib import Path
import pickle
import joblib
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

# ç¬¬ä¸‰æ–¹åº“
from cachetools import cached, TTLCache
from pydantic import BaseModel, validator, Field
from pydantic_settings import BaseSettings  # ä¿®å¤ï¼šv2 è¿ç§»
from dependency_injector import containers, providers
from dependency_injector.wiring import inject, Provide
from scipy.stats import ttest_1samp, norm, genpareto
import pytz

# å¼ºåŒ–å­¦ä¹ 
import gym
from gym import spaces
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
import torch

# æœºå™¨å­¦ä¹ 
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.isotonic import IsotonicRegression
from sklearn.calibration import CalibratedClassifierCV
from hmmlearn import hmm

# ç›‘æ§
from prometheus_client import start_http_server, Gauge, Counter, Histogram
import prometheus_client

# ==================== æ—¥å¿—ç³»ç»Ÿ ====================
LOG_DIR = "logs"
TRADE_LOG_FILE = "trade_log.csv"
PERF_LOG_FILE = "performance_log.csv"
SLIPPAGE_LOG_FILE = "slippage_log.csv"
EQUITY_CURVE_FILE = "equity_curve.csv"
REGIME_STATS_FILE = "regime_stats.csv"
CONSISTENCY_FILE = "consistency_stats.csv"
MODEL_DIR = "models"
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)

def append_to_csv(file_path: str, row: dict):
    file_exists = os.path.isfile(file_path)
    try:
        with open(file_path, 'a', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=row.keys())
            if not file_exists:
                writer.writeheader()
            writer.writerow(row)
    except Exception as e:
        print(f"å†™å…¥CSVå¤±è´¥: {e}")

def load_csv(file_path: str) -> pd.DataFrame:
    if os.path.exists(file_path):
        return pd.read_csv(file_path)
    return pd.DataFrame()

def append_to_log(file_name: str, message: str):
    date_str = datetime.now().strftime("%Y-%m-%d")
    log_path = os.path.join(LOG_DIR, f"{file_name}_{date_str}.log")
    try:
        with open(log_path, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}\n")
    except Exception as e:
        print(f"å†™å…¥æ—¥å¿—å¤±è´¥: {e}")

# ==================== é¢†åŸŸæ¨¡å‹ ====================
class SignalStrength(Enum):
    EXTREME = 0.85
    STRONG = 0.75
    HIGH = 0.65
    MEDIUM = 0.55
    WEAK = 0.50
    NONE = 0.0

class MarketRegime(Enum):
    TREND = "è¶‹åŠ¿"
    RANGE = "éœ‡è¡"
    PANIC = "ææ…Œ"
    CALM = "å¹³é™"
    HIGH_VOL = "é«˜æ³¢åŠ¨"
    LOW_VOL = "ä½æ³¢åŠ¨"

class OrderSide(Enum):
    BUY = "buy"
    SELL = "sell"

class OrderType(Enum):
    MARKET = "market"
    LIMIT = "limit"

@dataclass
class Signal:
    symbol: str
    direction: int  # 1: å¤š, -1: ç©º, 0: æ— 
    probability: float
    timestamp: datetime
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class Order:
    symbol: str
    side: OrderSide
    type: OrderType
    size: float
    price: Optional[float] = None
    stop_loss: Optional[float] = None
    take_profit: Optional[float] = None
    timestamp: datetime = field(default_factory=datetime.now)
    status: str = "pending"  # pending, filled, canceled
    exchange_order_id: Optional[str] = None
    filled_size: float = 0.0

@dataclass
class Position:
    symbol: str
    direction: int  # 1: long, -1: short
    entry_price: float
    entry_time: datetime
    size: float
    stop_loss: float
    take_profit: float
    partial_taken: bool = False
    real: bool = False
    highest_price: float = 0.0
    lowest_price: float = 1e9
    atr_mult: float = 1.5
    slippage_paid: float = 0.0
    price_history: Deque[float] = field(default_factory=lambda: deque(maxlen=20))
    impact_cost: float = 0.0

    def __post_init__(self):
        if self.direction == 1:
            self.highest_price = self.entry_price
        else:
            self.lowest_price = self.entry_price
        self.price_history.append(self.entry_price)

    def pnl(self, current_price: float) -> float:
        return (current_price - self.entry_price) * self.size * self.direction

    def stop_distance(self) -> float:
        if self.direction == 1:
            return self.entry_price - self.stop_loss
        else:
            return self.stop_loss - self.entry_price

    def update_stops(self, current_price: float, atr: float, atr_mult: float):
        self.price_history.append(current_price)
        if self.direction == 1:
            if current_price > self.highest_price:
                self.highest_price = current_price
            trailing_stop = self.highest_price - atr * atr_mult
            self.stop_loss = max(self.stop_loss, trailing_stop)
            new_tp = current_price + atr * atr_mult * 2.0
            self.take_profit = max(self.take_profit, new_tp)
            if current_price >= self.entry_price + self.stop_distance() * 1.5:
                self.stop_loss = max(self.stop_loss, self.entry_price)
        else:
            if current_price < self.lowest_price:
                self.lowest_price = current_price
            trailing_stop = self.lowest_price + atr * atr_mult
            self.stop_loss = min(self.stop_loss, trailing_stop)
            new_tp = current_price - atr * atr_mult * 2.0
            self.take_profit = min(self.take_profit, new_tp)
            if current_price <= self.entry_price - self.stop_distance() * 1.5:
                self.stop_loss = min(self.stop_loss, self.entry_price)

    def should_close(self, high: float, low: float, current_time: datetime, config: 'TradingConfig') -> Tuple[bool, str, float, Optional[float]]:
        if self.direction == 1:
            if low <= self.stop_loss:
                return True, "æ­¢æŸ", self.stop_loss, self.size
            if high >= self.take_profit:
                return True, "æ­¢ç›ˆ", self.take_profit, self.size
        else:
            if high >= self.stop_loss:
                return True, "æ­¢æŸ", self.stop_loss, self.size
            if low <= self.take_profit:
                return True, "æ­¢ç›ˆ", self.take_profit, self.size
        hold_hours = (current_time - self.entry_time).total_seconds() / 3600
        if hold_hours > config.max_hold_hours:
            return True, "è¶…æ—¶", (high + low) / 2, self.size
        if not self.partial_taken:
            if self.direction == 1 and high >= self.entry_price + self.stop_distance() * config.partial_tp_r_multiple:
                self.partial_taken = True
                partial_size = self.size * config.partial_tp_ratio
                self.size *= (1 - config.partial_tp_ratio)
                self.stop_loss = max(self.stop_loss, self.entry_price)
                return True, "éƒ¨åˆ†æ­¢ç›ˆ", self.entry_price + self.stop_distance() * config.partial_tp_r_multiple, partial_size
            if self.direction == -1 and low <= self.entry_price - self.stop_distance() * config.partial_tp_r_multiple:
                self.partial_taken = True
                partial_size = self.size * config.partial_tp_ratio
                self.size *= (1 - config.partial_tp_ratio)
                self.stop_loss = min(self.stop_loss, self.entry_price)
                return True, "éƒ¨åˆ†æ­¢ç›ˆ", self.entry_price - self.stop_distance() * config.partial_tp_r_multiple, partial_size
        return False, "", 0.0, None

@dataclass
class Trade:
    symbol: str
    direction: str
    entry_price: float
    exit_price: float
    size: float
    pnl: float
    reason: str
    timestamp: datetime
    slippage_entry: float = 0.0
    slippage_exit: float = 0.0
    impact_cost: float = 0.0

# ==================== é…ç½®ç®¡ç†ï¼ˆä¿®å¤ Pydantic v2ï¼‰====================
class TradingConfig(BaseSettings):
    """æ‰€æœ‰é…ç½®é¡¹ï¼Œæ”¯æŒä»ç¯å¢ƒå˜é‡æˆ–YAMLæ–‡ä»¶åŠ è½½"""
    # åŸºæœ¬å‚æ•°
    symbols: List[str] = ["ETH/USDT", "BTC/USDT", "SOL/USDT", "BNB/USDT"]
    risk_per_trade: float = 0.008
    daily_risk_budget_ratio: float = 0.025
    use_rl_position: bool = True
    rl_model_path: str = "models/rl_ppo.zip"
    rl_action_low: float = 0.5
    rl_action_high: float = 2.0
    max_consecutive_losses: int = 3
    cooldown_losses: int = 3
    cooldown_hours: int = 24
    max_drawdown_pct: float = 20.0
    circuit_breaker_atr: float = 5.0
    circuit_breaker_fg_extreme: Tuple[int, int] = (10, 90)
    atr_multiplier_base: float = 1.5
    atr_multiplier_min: float = 1.2
    atr_multiplier_max: float = 2.5
    tp_min_ratio: float = 2.0
    partial_tp_ratio: float = 0.5
    partial_tp_r_multiple: float = 1.2
    breakeven_trigger_pct: float = 1.5
    max_hold_hours: int = 36
    min_atr_pct: float = 0.5
    kelly_fraction: float = 0.25
    exchanges: Dict[str, str] = {
        "Binanceåˆçº¦": "binance",
        "Bybitåˆçº¦": "bybit",
        "OKXåˆçº¦": "okx"
    }
    data_sources: List[str] = ["binance", "bybit", "okx", "mexc", "kucoin"]
    timeframes: List[str] = ['1m', '5m', '15m', '1h', '4h', '1d']
    confirm_timeframes: List[str] = ['5m', '15m', '1h']
    timeframe_weights: Dict[str, int] = {'1d': 10, '4h': 7, '1h': 5, '15m': 3, '5m': 2, '1m': 1}
    fetch_limit: int = 2000
    auto_refresh_ms: int = 30000
    anti_duplicate_seconds: int = 180
    slippage_base: float = 0.0005
    slippage_impact_factor: float = 0.1
    slippage_imbalance_factor: float = 0.5
    fee_rate: float = 0.0004
    use_ml_factor: bool = True
    ml_retrain_interval: int = 3600
    ml_window: int = 500
    ml_n_estimators: int = 50
    ml_max_depth: int = 5
    use_prob_calibration: bool = True
    calibration_method: str = "isotonic"
    bayesian_prior_strength: float = 1.0
    factor_corr_threshold: float = 0.7
    factor_corr_penalty: float = 0.7
    ic_decay_rate: float = 0.99
    factor_eliminate_pvalue: float = 0.1
    factor_eliminate_ic: float = 0.02
    factor_min_weight: float = 0.1
    ic_window: int = 80
    factor_learning_rate: float = 0.3
    risk_budget_method: str = "risk_parity"
    black_litterman_tau: float = 0.05
    cov_matrix_window: int = 50
    max_sector_exposure: float = 0.3
    max_order_split: int = 3
    min_order_size: float = 0.001
    split_delay_seconds: int = 5
    regime_allow_trade: List[str] = ["è¶‹åŠ¿", "ææ…Œ"]
    night_start_hour: int = 0
    night_end_hour: int = 8
    night_risk_multiplier: float = 0.5
    volcone_percentiles: List[float] = [0.01, 0.05, 0.5, 0.95, 0.99]
    volcone_window: int = 100
    var_confidence: float = 0.95
    var_method: str = "HISTORICAL"
    portfolio_risk_target: float = 0.02
    var_aggressive_threshold: float = 1.0
    adapt_window: int = 20
    atr_price_history_len: int = 20
    funding_rate_threshold: float = 0.05
    max_leverage_global: float = 10.0
    max_reasonable_balance: float = 1e7
    max_reasonable_daily_pnl_ratio: float = 10.0
    regime_detection_method: str = "hmm"
    hmm_n_components: int = 3
    hmm_n_iter: int = 100
    cost_aware_training: bool = True
    sim_volatility: float = 0.06
    sim_trend_strength: float = 0.2
    bb_width_threshold: float = 0.1
    bb_window: int = 20
    rsi_range_low: int = 40
    rsi_range_high: int = 60
    use_chain_data: bool = False
    chain_api_key: str = ""
    use_orderflow: bool = False
    use_sentiment: bool = True
    auto_optimize_interval: int = 86400
    optimize_window: int = 30
    cost_model_version: str = "v2"
    drawdown_scaling_factor: float = 2.0
    var_scaling_factor: float = 1.5
    daily_loss_limit: float = 0.025
    cooldown_hours_risk: int = 12
    stress_scenarios: Dict[str, Dict[str, float]] = {
        'btc_crash_10': {'BTC/USDT': -0.10, 'ETH/USDT': -0.15},
        'vol_double': {'volatility_multiplier': 2.0},
        'liquidity_half': {'volume_multiplier': 0.5}
    }
    calibration_window: int = 200
    brier_score_window: int = 30
    walk_forward_train_pct: float = 0.7
    walk_forward_step: int = 100
    mc_simulations: int = 1000
    max_order_to_depth_ratio: float = 0.01
    latency_sim_ms: int = 200
    self_check_interval: int = 3600
    anomaly_threshold_ic_drop: float = 0.5

    # æ‰§è¡Œå±‚å‚æ•°
    leverage: int = 5
    order_sync_interval: int = 5

    # ç›‘æ§
    prometheus_port: int = 8000
    enable_prometheus: bool = False

    # å¯†é’¥é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡åŠ è½½ï¼‰
    binance_api_key: str = Field("", env="BINANCE_API_KEY")
    binance_secret_key: str = Field("", env="BINANCE_SECRET_KEY")
    telegram_token: str = Field("", env="TELEGRAM_TOKEN")
    telegram_chat_id: str = Field("", env="TELEGRAM_CHAT_ID")

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

def load_config() -> TradingConfig:
    config_file = Path("config.yaml")
    if config_file.exists():
        with open(config_file, "r") as f:
            data = yaml.safe_load(f)
        return TradingConfig(**data)
    else:
        return TradingConfig()

CONFIG = load_config()

# ==================== åŸºç¡€è®¾æ–½ ====================
class TelegramNotifier:
    # ... ä¸ä¹‹å‰ç›¸åŒ ...
    pass

class Logger:
    @staticmethod
    def error(msg: str): ...
    @staticmethod
    def info(msg: str): ...
    @staticmethod
    def warning(msg: str): ...

logger = Logger()

# ==================== ç›‘æ§ ====================
class PrometheusMetrics:
    def __init__(self, config: TradingConfig):
        self.config = config
        if config.enable_prometheus:
            start_http_server(config.prometheus_port)
        self.balance = Gauge('account_balance', 'Account balance in USDT')
        self.positions = Gauge('open_positions', 'Number of open positions')
        self.daily_pnl = Gauge('daily_pnl', 'Daily PnL')
        self.trades_total = Counter('trades_total', 'Total trades')
        self.trade_pnl = Histogram('trade_pnl', 'Trade PnL', buckets=[-100, -50, -10, 0, 10, 50, 100])
        self.slippage = Histogram('slippage', 'Slippage in USDT', buckets=[0.1, 0.5, 1.0, 2.0, 5.0])

    def update(self, trading_service: 'TradingService'):
        self.balance.set(trading_service.balance)
        self.positions.set(len(trading_service.positions))
        self.daily_pnl.set(trading_service.daily_pnl)

    def observe_trade(self, pnl: float, slippage: float):
        self.trade_pnl.observe(pnl)
        self.slippage.observe(slippage)

# ==================== å·¥å…·ç±»ï¼šæŒ‡æ ‡è®¡ç®—å™¨ ====================
class IndicatorCalculator:
    """å°è£…æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼Œæ¶ˆé™¤é‡å¤ä»£ç """
    @staticmethod
    def add_all_indicators(df: pd.DataFrame, config: TradingConfig) -> pd.DataFrame:
        df = df.copy()
        df['ema20'] = ta.trend.ema_indicator(df['close'], window=20)
        df['ema50'] = ta.trend.ema_indicator(df['close'], window=50)
        df['ema200'] = ta.trend.ema_indicator(df['close'], window=200)
        if len(df) >= 14:
            df['rsi'] = ta.momentum.rsi(df['close'], window=14)
            atr = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14)
            df['atr'] = atr
            df['atr_ma'] = atr.rolling(20).mean()
        else:
            df['rsi'] = np.nan
            df['atr'] = np.nan
            df['atr_ma'] = np.nan
        if len(df) >= 26:
            macd = ta.trend.MACD(df['close'])
            df['macd'] = macd.macd()
            df['macd_signal'] = macd.macd_signal()
            df['macd_diff'] = df['macd'] - df['macd_signal']
        else:
            df['macd'] = np.nan
            df['macd_signal'] = np.nan
            df['macd_diff'] = np.nan
        if len(df) >= 14:
            try:
                df['adx'] = ta.trend.adx(df['high'], df['low'], df['close'], window=14)
            except:
                df['adx'] = np.nan
        else:
            df['adx'] = np.nan
        if len(df) >= config.bb_window:
            bb = ta.volatility.BollingerBands(df['close'], window=config.bb_window, window_dev=2)
            df['bb_upper'] = bb.bollinger_hband()
            df['bb_lower'] = bb.bollinger_lband()
            df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['close']
            df['bb_factor'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
        else:
            df['bb_upper'] = np.nan
            df['bb_lower'] = np.nan
            df['bb_width'] = np.nan
            df['bb_factor'] = np.nan
        df['volume_sma'] = df['volume'].rolling(20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma']
        df['trend_factor'] = (df['close'] - df['ema20']) / df['close']
        if len(df) >= 6:
            df['future_ret'] = df['close'].pct_change(5).shift(-5)
        else:
            df['future_ret'] = np.nan
        return df

# ==================== æ•°æ®æä¾›è€…ï¼ˆå¼‚æ­¥ï¼Œä½¿ç”¨å·¥å…·ç±»ï¼‰====================
class AsyncDataProvider:
    def __init__(self, config: TradingConfig):
        self.config = config
        self.exchanges: Dict[str, ccxt_async.Exchange] = {}
        self.cache: Dict[str, TTLCache] = {}
        self.simulated_cache: Dict[str, Any] = {}
        self.indicator_calc = IndicatorCalculator()

    async def init(self):
        for name in self.config.data_sources:
            try:
                ex_class = getattr(ccxt_async, name)
                ex = ex_class({
                    'enableRateLimit': True,
                    'timeout': 30000,
                    'options': {'defaultType': 'future'}
                })
                self.exchanges[name] = ex
            except Exception:
                pass
        self._init_caches()

    def _init_caches(self):
        ttl_map = {
            '1m': 30,
            '5m': 60,
            '15m': 120,
            '1h': 3600,
            '4h': 14400,
            '1d': 86400
        }
        for tf in self.config.timeframes + self.config.confirm_timeframes:
            self.cache[tf] = TTLCache(maxsize=100, ttl=ttl_map.get(tf, 60))

    async def fetch_ohlcv(self, symbol: str, timeframe: str, limit: int) -> Optional[pd.DataFrame]:
        cache_key = f"{symbol}_{timeframe}_{limit}"
        if cache_key in self.cache[timeframe]:
            return self.cache[timeframe][cache_key]

        tasks = []
        for name in ["binance"] + [n for n in self.config.data_sources if n != "binance"]:
            if name in self.exchanges:
                tasks.append(self._fetch_single(name, symbol, timeframe, limit))
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for res in results:
            if isinstance(res, pd.DataFrame) and res is not None:
                self.cache[timeframe][cache_key] = res
                return res
        return None

    async def _fetch_single(self, exchange_name: str, symbol: str, timeframe: str, limit: int) -> Optional[pd.DataFrame]:
        try:
            ex = self.exchanges[exchange_name]
            ohlcv = await ex.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)
            if ohlcv and len(ohlcv) >= 50:
                df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                df = df.astype({col: float for col in ['open','high','low','close','volume']})
                return df
        except Exception as e:
            logger.warning(f"ä»{exchange_name}è·å–æ•°æ®å¤±è´¥: {e}")
        return None

    async def fetch_funding_rate(self, symbol: str) -> float:
        tasks = []
        for name in ["binance"] + [n for n in self.config.data_sources if n != "binance"]:
            if name in self.exchanges:
                tasks.append(self._fetch_funding_single(name, symbol))
        results = await asyncio.gather(*tasks, return_exceptions=True)
        rates = [r for r in results if isinstance(r, float)]
        return float(np.mean(rates)) if rates else 0.0

    async def _fetch_funding_single(self, exchange_name: str, symbol: str) -> Optional[float]:
        try:
            ex = self.exchanges[exchange_name]
            return (await ex.fetch_funding_rate(symbol))['fundingRate']
        except:
            return None

    async def fetch_orderbook_imbalance(self, symbol: str, depth: int = 10) -> float:
        for name in ["binance"] + [n for n in self.config.data_sources if n != "binance"]:
            if name in self.exchanges:
                try:
                    ex = self.exchanges[name]
                    ob = await ex.fetch_order_book(symbol, limit=depth)
                    bid_vol = sum(b[1] for b in ob['bids'])
                    ask_vol = sum(a[1] for a in ob['asks'])
                    total = bid_vol + ask_vol
                    return (bid_vol - ask_vol) / total if total > 0 else 0.0
                except Exception as e:
                    logger.warning(f"è·å–è®¢å•ç°¿å¤±è´¥: {e}")
        return 0.0

    async def fetch_fear_greed(self) -> int:
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get("https://api.alternative.me/fng/?limit=1", timeout=5) as resp:
                    data = await resp.json()
                    return int(data['data'][0]['value'])
        except Exception:
            return 50

    async def get_symbol_data(self, symbol: str, use_simulated: bool = False) -> Optional[Dict[str, Any]]:
        if use_simulated:
            cache_key = f"sim_{symbol}"
            if cache_key in self.simulated_cache:
                return self.simulated_cache[cache_key]
            sim_data = self.generate_simulated_data(symbol)
            result = {
                "data_dict": sim_data,
                "current_price": sim_data['15m']['close'].iloc[-1],
                "fear_greed": 50,
                "funding_rate": 0.0,
                "orderbook_imbalance": 0.0,
            }
            self.simulated_cache[cache_key] = result
            return result
        data_dict = await self.fetch_all_timeframes(symbol)
        if '15m' not in data_dict or data_dict['15m'].empty:
            return None
        current_price = float(data_dict['15m']['close'].iloc[-1])
        funding = await self.fetch_funding_rate(symbol)
        fear_greed = await self.fetch_fear_greed()
        imbalance = await self.fetch_orderbook_imbalance(symbol)
        return {
            "data_dict": data_dict,
            "current_price": current_price,
            "fear_greed": fear_greed,
            "funding_rate": funding,
            "orderbook_imbalance": imbalance,
        }

    async def fetch_all_timeframes(self, symbol: str) -> Dict[str, pd.DataFrame]:
        data_dict = {}
        all_tfs = list(set(self.config.timeframes + self.config.confirm_timeframes))
        tasks = [self.fetch_ohlcv(symbol, tf, self.config.fetch_limit) for tf in all_tfs]
        results = await asyncio.gather(*tasks)
        for tf, df in zip(all_tfs, results):
            if df is not None and len(df) >= 50:
                data_dict[tf] = self.indicator_calc.add_all_indicators(df, self.config)
        return data_dict

    def generate_simulated_data(self, symbol: str, limit: int = 2000) -> Dict[str, pd.DataFrame]:
        seed = int(hashlib.md5(symbol.encode()).hexdigest()[:8], 16) % 2**32
        np.random.seed(seed)
        end = datetime.now()
        timestamps = pd.date_range(end=end, periods=limit, freq='15min')
        
        if 'BTC' in symbol:
            base = 40000
            volatility = self.config.sim_volatility * 0.6
            trend_factor = 0.1
        elif 'ETH' in symbol:
            base = 2100
            volatility = self.config.sim_volatility
            trend_factor = 0.15
        else:
            base = 100
            volatility = self.config.sim_volatility * 1.2
            trend_factor = 0.2
        
        t = np.linspace(0, 6*np.pi, limit)
        trend_direction = np.random.choice([-1, 1], p=[0.3, 0.7])
        trend = trend_direction * self.config.sim_trend_strength * np.linspace(0, 1, limit) * base * trend_factor
        cycle1 = 0.03 * base * np.sin(t * 1)
        cycle2 = 0.015 * base * np.sin(t * 3)
        cycle3 = 0.007 * base * np.sin(t * 7)
        random_step = np.random.randn(limit) * volatility * base
        random_walk = np.cumsum(random_step) * 0.15
        price_series = base + trend + cycle1 + cycle2 + cycle3 + random_walk
        price_series = np.maximum(price_series, base * 0.3)
        
        opens = price_series * (1 + np.random.randn(limit) * 0.0015)
        closes = price_series * (1 + np.random.randn(limit) * 0.0025)
        highs = np.maximum(opens, closes) + np.abs(np.random.randn(limit)) * volatility * price_series * 0.5
        lows = np.minimum(opens, closes) - np.abs(np.random.randn(limit)) * volatility * price_series * 0.5
        volume_base = np.random.randint(800, 8000, limit)
        volume_factor = 1 + 3 * np.abs(np.diff(price_series, prepend=price_series[0])) / price_series
        volumes = (volume_base * volume_factor).astype(int)
        
        df_15m = pd.DataFrame({
            'timestamp': timestamps,
            'open': opens,
            'high': highs,
            'low': lows,
            'close': closes,
            'volume': volumes
        })
        df_15m = self.indicator_calc.add_all_indicators(df_15m, self.config)
        
        data_dict = {'15m': df_15m}
        for tf in ['1m', '5m', '1h', '4h', '1d']:
            resampled = df_15m.resample(tf, on='timestamp').agg({
                'open': 'first',
                'high': 'max',
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
            }).dropna().reset_index()
            if len(resampled) >= 30:
                resampled = self.indicator_calc.add_all_indicators(resampled, self.config)
                data_dict[tf] = resampled
        return data_dict

    async def close(self):
        for ex in self.exchanges.values():
            await ex.close()

    # æ–°å¢ï¼šè·å–å†å²æ•°æ®ç”¨äºå›æµ‹ï¼ˆä»äº¤æ˜“æ‰€æˆ–æœ¬åœ°æ–‡ä»¶ï¼‰
    async def fetch_historical_data(self, symbol: str, timeframe: str, start: datetime, end: datetime) -> Optional[pd.DataFrame]:
        # å°è¯•ä»äº¤æ˜“æ‰€è·å–
        exchange = self.exchanges.get('binance')
        if exchange:
            since = exchange.parse8601(start.isoformat())
            all_ohlcv = []
            while since < exchange.parse8601(end.isoformat()):
                ohlcv = await exchange.fetch_ohlcv(symbol, timeframe, since=since, limit=1000)
                if not ohlcv:
                    break
                all_ohlcv.extend(ohlcv)
                since = ohlcv[-1][0] + 1
            if all_ohlcv:
                df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                df = df[(df['timestamp'] >= start) & (df['timestamp'] <= end)]
                return self.indicator_calc.add_all_indicators(df, self.config)
        # å›é€€åˆ°æœ¬åœ°CSV
        file_path = f"data/{symbol}_{timeframe}_{start.date()}_{end.date()}.csv"
        if os.path.exists(file_path):
            df = pd.read_csv(file_path)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            return self.indicator_calc.add_all_indicators(df, self.config)
        return None

# ==================== ç­–ç•¥å¼•æ“ï¼ˆä½¿ç”¨å·¥å…·ç±»ï¼‰====================
class StrategyEngine:
    # ... å¤§éƒ¨åˆ†ä¸ä¹‹å‰ç›¸åŒï¼Œä½†ä½¿ç”¨ IndicatorCalculator å·²å°è£…æŒ‡æ ‡ï¼Œæ­¤å¤„çœç•¥é‡å¤ä»£ç  ...
    # æ³¨æ„ï¼šåœ¨éœ€è¦è®¡ç®—æŒ‡æ ‡çš„åœ°æ–¹è°ƒç”¨ IndicatorCalculator.add_all_indicators
    pass

# ==================== å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼ˆè§‚æµ‹ç©ºé—´ä¸°å¯Œï¼‰====================
class TradingEnv(gym.Env):
    def __init__(self, data_provider: AsyncDataProvider, config: TradingConfig):
        super(TradingEnv, self).__init__()
        self.data_provider = data_provider
        self.config = config
        self.action_space = spaces.Box(low=config.rl_action_low, high=config.rl_action_high, shape=(1,), dtype=np.float32)
        # è§‚æµ‹ç©ºé—´ï¼šå‡€å€¼ã€æŒä»“æ¯”ä¾‹ã€æ³¢åŠ¨ç‡ã€è¶‹åŠ¿å¼ºåº¦ã€ä¿¡å·æ¦‚ç‡ç­‰
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(10,), dtype=np.float32)
        self.reset()

    def reset(self):
        self.current_step = 0
        self.balance = 10000
        self.position = 0
        self.entry_price = 0
        self.trades = []
        return self._get_obs()

    async def _get_obs(self):
        # ä» data_provider è·å–æœ€æ–°å¸‚åœºæ•°æ®
        # ç®€åŒ–ç¤ºä¾‹ï¼šå‡è®¾è·å–ETH/USDTçš„15mæ•°æ®
        data = await self.data_provider.get_symbol_data('ETH/USDT', use_simulated=True)
        if data:
            df = data['data_dict']['15m']
            last = df.iloc[-1]
            # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆæœ€è¿‘20æ ¹ATRå‡å€¼ï¼‰
            vol = last['atr'] / last['close'] if not pd.isna(last['atr']) else 0.02
            # è¶‹åŠ¿å¼ºåº¦ï¼ˆADXï¼‰
            trend = last['adx'] / 100 if not pd.isna(last['adx']) else 0.5
            # ä¿¡å·æ¦‚ç‡ï¼ˆæ¨¡æ‹Ÿï¼‰
            signal_prob = np.random.rand()
        else:
            vol, trend, signal_prob = 0.02, 0.5, 0.5

        obs = np.array([
            self.balance / 10000,
            self.position / 100,  # å‡è®¾æœ€å¤§æŒä»“100
            vol,
            trend,
            signal_prob,
            0, 0, 0, 0, 0
        ], dtype=np.float32)
        return obs

    def step(self, action):
        # æ‰§è¡ŒåŠ¨ä½œï¼ˆæ¨¡æ‹Ÿäº¤æ˜“ï¼‰ï¼Œè®¡ç®—å¥–åŠ±ï¼ˆå¤æ™®æ¯”ç‡ï¼‰
        # ... ä¸ä¹‹å‰ç›¸åŒ ...
        return self._get_obs(), reward, done, {}

# ==================== å›æµ‹å¼•æ“ï¼ˆå¢å¼ºï¼šçœŸå®æ•°æ®ã€æ»‘ç‚¹ã€æ‰‹ç»­è´¹ï¼‰====================
class BacktestEngine:
    def __init__(self, config: TradingConfig, strategy_engine: StrategyEngine, risk_manager: RiskManager,
                 data_provider: AsyncDataProvider, execution_service: ExecutionService):
        self.config = config
        self.strategy_engine = strategy_engine
        self.risk_manager = risk_manager
        self.data_provider = data_provider
        self.execution_service = execution_service

    async def run(self, symbols: List[str], start_date: datetime, end_date: datetime,
                  initial_balance: float = 10000, use_real_data: bool = False) -> Dict[str, Any]:
        # è·å–å†å²æ•°æ®
        all_data = {}
        for sym in symbols:
            if use_real_data:
                # ä»äº¤æ˜“æ‰€æˆ–æ–‡ä»¶åŠ è½½çœŸå®æ•°æ®
                df = await self.data_provider.fetch_historical_data(sym, '15m', start_date, end_date)
                if df is None:
                    logger.error(f"æ— æ³•è·å– {sym} çš„å†å²æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                    df = self.data_provider.generate_simulated_data(sym)['15m']
            else:
                df = self.data_provider.generate_simulated_data(sym)['15m']
            all_data[sym] = df

        # æŒ‰æ—¶é—´å¯¹é½
        timestamps = None
        for sym, df in all_data.items():
            if timestamps is None:
                timestamps = df['timestamp']
            else:
                common = pd.merge(pd.DataFrame({'timestamp': timestamps}), pd.DataFrame({'timestamp': df['timestamp']}), on='timestamp')
                timestamps = common['timestamp']

        balance = initial_balance
        positions: Dict[str, Position] = {}
        trades = []
        equity_curve = []

        for idx, ts in enumerate(timestamps):
            # æ„å»ºå½“å‰æ—¶åˆ»æ•°æ®åˆ‡ç‰‡
            current_data = {}
            for sym in symbols:
                row = all_data[sym][all_data[sym]['timestamp'] == ts]
                if not row.empty:
                    current_data[sym] = row.iloc[-1]

            if not current_data:
                continue

            # å¹³ä»“æ£€æŸ¥ï¼ˆå¤ç”¨ Position.should_closeï¼‰
            for sym, pos in list(positions.items()):
                if sym not in current_data:
                    continue
                high = current_data[sym]['high']
                low = current_data[sym]['low']
                should_close, reason, exit_price, close_size = pos.should_close(high, low, ts, self.config)
                if should_close:
                    # æ¨¡æ‹Ÿæ»‘ç‚¹
                    slippage = self.execution_service._advanced_slippage_prediction(
                        exit_price, close_size,
                        current_data[sym]['volume'], 0.02, 0  # ç®€åŒ–
                    )
                    actual_exit = exit_price - slippage if pos.direction == 1 else exit_price + slippage
                    pnl = (actual_exit - pos.entry_price) * close_size * pos.direction - actual_exit * close_size * self.config.fee_rate * 2
                    balance += pnl
                    trades.append({
                        'symbol': sym,
                        'entry': pos.entry_price,
                        'exit': actual_exit,
                        'size': close_size,
                        'pnl': pnl,
                        'reason': reason,
                        'time': ts,
                        'slippage': slippage
                    })
                    if close_size >= pos.size:
                        del positions[sym]
                    else:
                        pos.size -= close_size

            # ç”Ÿæˆä¿¡å·
            # æ„å»ºdf_dictï¼ˆéœ€è¦å¤šå‘¨æœŸï¼Œç®€åŒ–åªä½¿ç”¨15mï¼‰
            df_dict = {sym: {'15m': all_data[sym][all_data[sym]['timestamp'] <= ts]} for sym in symbols}
            signals = self.strategy_engine.generate_signals(
                {sym: {'data_dict': df_dict[sym]} for sym in symbols},
                fear_greed=50,  # å›æµ‹æ—¶æ— æ³•è·å–å®æ—¶ææƒ§è´ªå©ªï¼Œå¯ä½¿ç”¨å†å²æˆ–é»˜è®¤
                market_regime=MarketRegime.RANGE
            )

            # å¼€ä»“
            for sig in signals:
                if sig.symbol not in positions:
                    price = current_data[sig.symbol]['close']
                    atr = current_data[sig.symbol]['atr'] if not pd.isna(current_data[sig.symbol]['atr']) else price * 0.01
                    recent = np.array([0.01] * 20)  # ç®€åŒ–
                    size = self.risk_manager.calc_position_size(
                        balance, sig.probability, atr, price, recent,
                        is_aggressive=False,
                        equity_curve=[], cov_matrix=None,
                        positions=positions, current_symbols=symbols,
                        symbol_current_prices={sym: current_data[sym]['close'] for sym in current_data}
                    )
                    if size > 0:
                        stop_dist = atr * self.config.atr_multiplier_base
                        stop = price - stop_dist if sig.direction == 1 else price + stop_dist
                        take = price + stop_dist * self.config.tp_min_ratio if sig.direction == 1 else price - stop_dist * self.config.tp_min_ratio
                        pos = Position(
                            symbol=sig.symbol,
                            direction=sig.direction,
                            entry_price=price,
                            entry_time=ts,
                            size=size,
                            stop_loss=stop,
                            take_profit=take,
                            initial_atr=atr
                        )
                        positions[sig.symbol] = pos

            # è®°å½•æƒç›Š
            total_value = balance
            for sym, pos in positions.items():
                if sym in current_data:
                    total_value += pos.pnl(current_data[sym]['close'])
            equity_curve.append({'time': ts, 'equity': total_value})

        # è®¡ç®—ç»©æ•ˆ
        returns = pd.Series([e['equity'] for e in equity_curve]).pct_change().dropna()
        sharpe = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0
        max_dd = (pd.Series([e['equity'] for e in equity_curve]).cummax() - pd.Series([e['equity'] for e in equity_curve])).max()

        return {
            'initial_balance': initial_balance,
            'final_balance': balance,
            'total_return': (balance - initial_balance) / initial_balance * 100,
            'sharpe': sharpe,
            'max_drawdown': max_dd,
            'trades': trades,
            'equity_curve': equity_curve
        }

# ==================== é£é™©ç®¡ç†ã€æ‰§è¡ŒæœåŠ¡ã€äº¤æ˜“æœåŠ¡ç­‰ï¼ˆç•¥ï¼‰====================
# ç”±äºç¯‡å¹…é™åˆ¶ï¼ŒRiskManagerã€ExecutionServiceã€TradingService ä¸54.0ç‰ˆæœ¬åŸºæœ¬ç›¸åŒï¼Œ
# ä½†éœ€è¦åœ¨æ‰§è¡ŒæœåŠ¡ä¸­å¢åŠ æ»‘ç‚¹ç›´æ–¹å›¾æ›´æ–°ï¼š
# åœ¨ ExecutionService._execute_order ä¸­ï¼Œå½“æœ‰å®é™…æˆäº¤æ—¶ï¼Œè°ƒç”¨ metrics.observe_trade(pnl, slippage)

# ==================== ä¾èµ–æ³¨å…¥å®¹å™¨ ====================
class Container(containers.DeclarativeContainer):
    config = providers.Singleton(load_config)
    notifier = providers.Singleton(TelegramNotifier, config=config)
    data_provider = providers.Singleton(AsyncDataProvider, config=config)
    strategy_engine = providers.Singleton(StrategyEngine, config=config, data_provider=data_provider)
    rl_manager = providers.Singleton(RLManager, config=config, data_provider=data_provider)
    risk_manager = providers.Singleton(RiskManager, config=config, strategy_engine=strategy_engine, rl_manager=rl_manager)
    execution_service = providers.Singleton(ExecutionService, config=config, notifier=notifier)
    trading_service = providers.Singleton(
        TradingService,
        config=config,
        data_provider=data_provider,
        strategy_engine=strategy_engine,
        risk_manager=risk_manager,
        execution_service=execution_service,
        notifier=notifier
    )
    backtest_engine = providers.Singleton(BacktestEngine, config=config, strategy_engine=strategy_engine,
                                          risk_manager=risk_manager, data_provider=data_provider,
                                          execution_service=execution_service)
    metrics = providers.Singleton(PrometheusMetrics, config=config)

# ==================== Streamlit UIï¼ˆä¸54.0ç±»ä¼¼ï¼Œç•¥ï¼‰====================

if __name__ == "__main__":
    main()
